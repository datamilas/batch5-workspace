{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "\n",
    "import dataframe_image as dfi\n",
    "\n",
    "import joblib\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_metrics(y_test, y_pred):\n",
    "    predicted_for_discharge = list(np.where(y_pred == False)[0])\n",
    "    wrongful_discharge = y_test.reset_index(drop=True).iloc[predicted_for_discharge].sum()/len(predicted_for_discharge)\n",
    "    print(f\"WRONGFUL DISCHARGE RATE: {wrongful_discharge}\")\n",
    "\n",
    "    print(f\"F1_SCORE: {f1_score(y_test, y_pred)}\")\n",
    "    print(f\"RECALL: {recall_score(y_test, y_pred)}\")\n",
    "    print(f\"PRECISION: {precision_score(y_test, y_pred)}\")\n",
    "\n",
    "    \n",
    "\n",
    "    try:\n",
    "        print(f\"ROC AUC: {roc_auc_score(y_test, y_pred)}\")\n",
    "    except: \"ROC AUC curve could not be calculated\"\n",
    "\n",
    "def add_numerical_features(data, column):\n",
    "    data[f\"{column}_squared\"] = np.square(data[column]-data[column].mean())\n",
    "    data[f\"{column}_sqrt\"] = np.sqrt(data[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admission_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_code</th>\n",
       "      <th>discharge_disposition_code</th>\n",
       "      <th>admission_source_code</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>...</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>hemoglobin_level</th>\n",
       "      <th>blood_transfusion</th>\n",
       "      <th>max_glu_serum</th>\n",
       "      <th>A1Cresult</th>\n",
       "      <th>diuretics</th>\n",
       "      <th>insulin</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>199042938</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[50-60)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>A+</td>\n",
       "      <td>14.5</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>91962954</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>B+</td>\n",
       "      <td>15.7</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>&gt;7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>157495374</td>\n",
       "      <td>African American</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>AB-</td>\n",
       "      <td>13.5</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>&gt;8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>82692360</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>A+</td>\n",
       "      <td>13.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>218016576</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>A+</td>\n",
       "      <td>13.1</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   admission_id  patient_id              race  gender      age weight  \\\n",
       "0             0   199042938         Caucasian    Male  [50-60)    NaN   \n",
       "1             1    91962954         Caucasian    Male  [80-90)    NaN   \n",
       "2             3   157495374  African American  Female  [70-80)    NaN   \n",
       "3             4    82692360         Caucasian  Female      NaN    NaN   \n",
       "4             5   218016576         Caucasian  Female  [70-80)    NaN   \n",
       "\n",
       "   admission_type_code  discharge_disposition_code  admission_source_code  \\\n",
       "0                  3.0                         1.0                    1.0   \n",
       "1                  2.0                         1.0                    7.0   \n",
       "2                  NaN                         1.0                    NaN   \n",
       "3                  1.0                        22.0                    7.0   \n",
       "4                  2.0                         1.0                    1.0   \n",
       "\n",
       "   time_in_hospital  ... blood_type hemoglobin_level  blood_transfusion  \\\n",
       "0                 1  ...         A+             14.5              False   \n",
       "1                 3  ...         B+             15.7              False   \n",
       "2                 2  ...        AB-             13.5              False   \n",
       "3                12  ...         A+             13.0              False   \n",
       "4                 4  ...         A+             13.1              False   \n",
       "\n",
       "  max_glu_serum  A1Cresult  diuretics  insulin  change  diabetesMed  \\\n",
       "0          None       None         No       No      No          Yes   \n",
       "1          None         >7         No       No      No           No   \n",
       "2          None         >8         No       No      No          Yes   \n",
       "3          None       None         No       No      No           No   \n",
       "4          None       None         No       No      No          Yes   \n",
       "\n",
       "   readmitted  \n",
       "0       False  \n",
       "1        True  \n",
       "2       False  \n",
       "3       False  \n",
       "4        True  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/cleaned_data.csv\")\n",
    "\n",
    "## change target value to boolean\n",
    "data.readmitted = data.readmitted.replace([\"Yes\", \"No\"], [True, False])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONGFUL DISCHARGE RATE: nan\n",
      "F1_SCORE: 0.20393259701086341\n",
      "RECALL: 1.0\n",
      "PRECISION: 0.11354395535015278\n",
      "ROC AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "#dummy model: predicting everything as true\n",
    "get_metrics(data.readmitted, [True]*len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONGFUL DISCHARGE RATE: 0.11360075211532435\n",
      "F1_SCORE: 0.11310053380782918\n",
      "RECALL: 0.11310053380782918\n",
      "PRECISION: 0.11310053380782918\n",
      "ROC AUC: 0.49974989084625243\n"
     ]
    }
   ],
   "source": [
    "#dummy model2 - predict same rate of readmission as in dataset\n",
    "predict_same_rate = data.readmitted.sample(frac=1).reset_index(drop=True)\n",
    "get_metrics(data.readmitted, predict_same_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnosis_decoder(code):\n",
    "    if \"V\" in str(code): \n",
    "        return \"External causes of injury and supplemental classification\"\n",
    "    elif \"E\" in str(code):\n",
    "        return \"External causes of injury and supplemental classification\"\n",
    "    else:\n",
    "        try:\n",
    "        \n",
    "            code = int(code)\n",
    "            if code<140: return \"infectious and parasitic diseases\"\n",
    "            if code<240: return \"neoplasms\"\n",
    "            if code<280: return \"endocrine, nutritional and metabolic diseases, and immunity disorders\"\n",
    "            if code<290: return \"diseases of the blood and blood-forming organs\"\n",
    "            if code<320: return \"mental disorders\"\n",
    "            if code<390: return \"diseases of the nervous system and sense organs\"\n",
    "            if code<460: return \"diseases of the circulatory system\"\n",
    "            if code<520: return \"diseases of the respiratory system\"\n",
    "            if code<580: return \"diseases of the digestive system\"\n",
    "            if code<630: return \"diseases of the genitourinary system\"\n",
    "            if code<680: return \"complications of pregnancy, childbirth, and the puerperium\"\n",
    "            if code<710: return \"diseases of the skin and subcutaneous tissue\"\n",
    "            if code<740: return \"diseases of the musculoskeletal system and connective tissue\"\n",
    "            if code<760: return \"congenital anomalies\"\n",
    "            if code<780: return \"certain conditions originating in the perinatal period\"\n",
    "            if code<800: return \"symptoms, signs, and ill-defined conditions\"\n",
    "            if code<1000: return \"injury and poisoning\"\n",
    "        except:\n",
    "            return(np.nan)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code age groups as integers\n",
    "data[\"age_as_int\"] = data.age.replace(['[50-60)', '[80-90)', '[60-70)', '[70-80)', '[40-50)', '[30-40)',\n",
    " '[90-100)', '[20-30)', '[10-20)', '[0-10)'], [50, 80, 60, 70, 40, 30, 90, 20, 10, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def was_test_done(data, column_name, not_done=\"None\"):\n",
    "    data[column_name+\"_done\"] = np.where(data[column_name]==not_done, \"No\", \"Yes\")\n",
    "    data[column_name+\"_done\"] = data[column_name].replace(\"nan\", np.nan)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, True, False], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#is patient insured\n",
    "payer_codes = list(data.payer_code.dropna().unique())\n",
    "payer_codes.remove(\"SP\")\n",
    "\n",
    "data[\"isInsured\"] = data.payer_code.replace(list(payer_codes), True)\n",
    "data[\"isInsured\"] = data.isInsured.replace(\"SP\", False)\n",
    "data[\"isInsured\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_common_categories(data, column_name, threshold):\n",
    "    common_categories = list(data[column_name].value_counts()[data[column_name].value_counts()>threshold].index.values)\n",
    "    common_categories.append(np.nan)\n",
    "    data[column_name] = np.where(data[column_name].isin(common_categories), data[column_name], 'Other')\n",
    "    data[column_name] = data[column_name].replace(\"nan\", np.nan)\n",
    "    return common_categories\n",
    "\n",
    "\n",
    "threshold=100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MC',\n",
       " 'HM',\n",
       " 'SP',\n",
       " 'BC',\n",
       " 'MD',\n",
       " 'CP',\n",
       " 'UN',\n",
       " 'CM',\n",
       " 'OG',\n",
       " 'PO',\n",
       " 'DM',\n",
       " 'CH',\n",
       " 'WC',\n",
       " nan]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep only common values for payer_code, set others as \"Other\"\n",
    "column_name = \"payer_code\"\n",
    "filter_common_categories(data, column_name, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 3.0, 2.0, nan]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep only common values for admission_type_code, set others as \"Other\"\n",
    "column_name = \"admission_type_code\"\n",
    "filter_common_categories(data, column_name, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 3.0, 6.0, 2.0, 22.0, 5.0, 4.0, 7.0, 23.0, 28.0, nan]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep only common values for discharge disposition, set others as \"Other\"\n",
    "column_name = \"discharge_disposition_code\"\n",
    "filter_common_categories(data, column_name, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.0, 1.0, 4.0, 6.0, 2.0, 5.0, 3.0, nan]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep only common values for admission_source_code, set others as \"Other\"\n",
    "column_name = \"admission_source_code\"\n",
    "filter_common_categories(data, column_name, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['InternalMedicine',\n",
       " 'Emergency/Trauma',\n",
       " 'Family/GeneralPractice',\n",
       " 'Cardiology',\n",
       " 'Surgery-General',\n",
       " 'Nephrology',\n",
       " 'Orthopedics',\n",
       " 'Orthopedics-Reconstructive',\n",
       " 'Radiologist',\n",
       " 'Pulmonology',\n",
       " 'Psychiatry',\n",
       " 'Urology',\n",
       " 'ObstetricsandGynecology',\n",
       " 'Surgery-Cardiovascular/Thoracic',\n",
       " 'Gastroenterology',\n",
       " 'Surgery-Vascular',\n",
       " 'Surgery-Neuro',\n",
       " 'PhysicalMedicineandRehabilitation',\n",
       " 'Oncology',\n",
       " 'Pediatrics',\n",
       " 'Neurology',\n",
       " 'Hematology/Oncology',\n",
       " 'Pediatrics-Endocrinology',\n",
       " 'Otolaryngology',\n",
       " nan]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep only common values for medical_specialty set others as \"Other\"\n",
    "column_name = \"medical_specialty\"\n",
    "filter_common_categories(data, column_name, threshold)\n",
    "#data[column_name].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simplify diagnosis codes\n",
    "diag_columns = ['diag_1','diag_2','diag_3']\n",
    "for col in diag_columns:\n",
    "    data[f\"{col}_simplified\"] = data[col].str.replace(r\"\\.(.*)\", \"\")  #remove any numbers that come after .\n",
    "    data[f\"{col}_simplified\"] = data.apply(lambda row: diagnosis_decoder(row[f\"{col}_simplified\"]),axis=1)\n",
    "\n",
    "    column_name = f\"{col}_simplified\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"admission_id\", \"patient_id\", \"age\", \"weight\", \"diag_1\", \"diag_2\", \"diag_3\", \"blood_type\", \"payer_code\", \"medical_specialty\", \"isInsured\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(list(zip((data.isnull().sum()/len(data)*100).values, data.nunique().values, data.dtypes.values)),  \n",
    "    columns=[\"% of missing values\", \"Number of unique values\", \"Data type\"], index=data.columns).drop(\"readmitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0301/114238.567917:ERROR:gpu_init.cc(441)] Passthrough is not supported, GL is swiftshader\n",
      "[0301/114239.114742:INFO:headless_shell.cc(648)] Written to file /tmp/tmpd2i_tyot/temp.png.\n"
     ]
    }
   ],
   "source": [
    "dfi.export(features_df, \"features_used.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/data1_to_model\", index=False)\n",
    "new_data = pd.read_csv(\"data/first_round_to_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.concat([data, new_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.readmitted = data.readmitted.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = data.columns\n",
    "numerical_features = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = data.select_dtypes(include=['O', 'bool']).drop([\"readmitted\"], axis=1).columns\n",
    "\n",
    "data[numerical_features] = data[numerical_features].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression(random_state=42, n_jobs=-1, max_iter=10000),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    SVC(random_state=42)\n",
    "\n",
    "    \n",
    "]\n",
    "\n",
    "parameters = [\n",
    "              {\"C\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100], \"penalty\": ['none', 'l1', 'l2', 'elasticnet']},\n",
    "\n",
    "              {\"max_depth\": [1, 3, 5, 7, 9]},\n",
    "\n",
    "              {'n_estimators': [100, 200, 500, 1000], 'max_depth' : [1, 3, 5, 7, 9]},\n",
    "\n",
    "              {'n_estimators': [100, 200, 500, 1000], 'max_depth' : [1, 3, 5, 7, 9]},\n",
    "\n",
    "               {'kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], 'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]},\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "              \n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def define_pipeline(classifier, params):\n",
    "\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        #('scaler', RobustScaler())])\n",
    "\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=np.nan)),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    feature_selection = Pipeline(steps = [\n",
    "    ('feature_selection', SelectFromModel(LogisticRegression())),\n",
    "    ])\n",
    "\n",
    "    pipeline = make_pipeline(\n",
    "        preprocessor,\n",
    "        #feature_selection,\n",
    "        GridSearchCV(classifier,\n",
    "                    param_grid=params,\n",
    "                    cv=5, scoring=\"f1\",\n",
    "                    refit=True)\n",
    "\n",
    "    )\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()\n",
    "X_train = df_train[all_features]\n",
    "y_train = df_train[target]\n",
    "\n",
    "\n",
    "# define oversampling strategy\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "# fit and apply the transform\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# define undersampling strategy\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "# fit and apply the transform\n",
    "X_under, y_under = undersample.fit_resample(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40123, 28) (23759, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save sets\n",
    "all_data = pd.read_csv(\"data/cleaned_data.csv\")\n",
    "\n",
    "#is patient insured\n",
    "payer_codes = list(all_data.payer_code.dropna().unique())\n",
    "payer_codes.remove(\"SP\")\n",
    "\n",
    "all_data[\"isInsured\"] = all_data.payer_code.replace(list(payer_codes), True)\n",
    "all_data[\"isInsured\"] = all_data.isInsured.replace(\"SP\", False)\n",
    "all_data[\"isInsured\"].unique()\n",
    "\n",
    "\n",
    "df_train_to_save = df_train.merge(all_data.iloc[df_train.index][[\"age\", \"medical_specialty\", \"isInsured\"]], left_index=True, right_index=True)\n",
    "df_test_to_save = df_test.merge(all_data.iloc[df_test.index][[\"age\", \"medical_specialty\", \"isInsured\"]], left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "#df_train_to_save.to_csv(\"train_set.csv\")\n",
    "#X_under.to_csv(\"train_set_under_X.csv\")\n",
    "#y_under.to_csv(\"train_set_under_y.csv\")\n",
    "#df_test_to_save.to_csv(\"test_set.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_under = pd.read_csv(\"train_set_under_X.csv\")\n",
    "#y_under = pd.read_csv(\"train_set_under_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_under.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "#y_under.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test = pd.read_csv(\"test_set.csv\")\n",
    "#df_train = pd.read_csv(\"train_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_features = X_under.columns\n",
    "#target = y_under.columns\n",
    "#X_train = df_train[all_features]\n",
    "#y_train = df_train[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifiers = [RandomForestClassifier(n_jobs=-1, random_state=42)]\n",
    "#parameters = [{'n_estimators': [500], 'max_depth' : [5]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_jobs=-1, random_state=42)\n",
      "{'max_depth': 5, 'n_estimators': 500}\n",
      "WRONGFUL DISCHARGE RATE: 0.11401995033461004\n",
      "F1_SCORE: 0.0\n",
      "RECALL: 0.0\n",
      "PRECISION: 0.0\n",
      "ROC AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "best_params = []\n",
    "for classifier, params in zip(classifiers, parameters):\n",
    "    pipeline = define_pipeline(classifier, params)\n",
    "\n",
    "    print(classifier)\n",
    "    #pipeline.fit(X_under, y_under)\n",
    "    #pipeline.fit(pd.DataFrame.sparse.from_spmatrix(X_under), pd.DataFrame.sparse.from_spmatrix(y_under))\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    print(pipeline.named_steps['gridsearchcv'].best_params_)\n",
    "     \n",
    "    #make predictions\n",
    "    X_test = df_test[all_features]\n",
    "\n",
    "    y_test = df_test[target]\n",
    "\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    preds_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    get_metrics(y_test, y_pred)\n",
    "    \n",
    "    best_params.append(pipeline.named_steps['gridsearchcv'].best_params_)\n",
    "\n",
    "    #joblib.dump(pipeline, f'pipeline_{str(classifier)}.pickle')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONGFUL DISCHARGE RATE: readmitted    0.071043\n",
      "dtype: float64\n",
      "F1_SCORE: 0.26649650927107577\n",
      "RECALL: 0.6552233296419343\n",
      "PRECISION: 0.16726347531096872\n",
      "ROC AUC: 0.6177066766974517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pipeline_RandomForestClassifier(n_jobs=-1, random_state=42).pickle']"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(y_test, y_pred)\n",
    "    \n",
    "best_params.append(pipeline.named_steps['gridsearchcv'].best_params_)\n",
    "\n",
    "joblib.dump(pipeline, f'pipeline_{str(classifier)}.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_df = pd.DataFrame([best_params], columns=[\"LogisticRegression\", \"DecisionTreeClassifier\", \"RandomForestClassifier\", \"GradientBoostingClassifier\", \"SVC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_df.to_csv(\"hyperparameters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "105b385371de027687b7b6ee2a9870daf2e0ed9752ad5f6ba523ea4490bef3d5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('capstone': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
