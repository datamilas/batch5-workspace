{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a0c9ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f881c7002cca9b48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Hackthon 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5d0de0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4efa4dd0f5a58872",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# importing needed packages here\n",
    "\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from spacy.matcher import Matcher\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def _hash(s):\n",
    "    return hashlib.sha256(\n",
    "        bytes(str(s), encoding='utf8'),\n",
    "    ).hexdigest()\n",
    "\n",
    "cpu_count = int(os.cpu_count()) if os.cpu_count() != None else 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "642ba60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.0-py3-none-manylinux2014_x86_64.whl (173.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 173.5 MB 21 kB/s  eta 0:00:01   |▍                               | 1.9 MB 2.4 MB/s eta 0:01:13     |███████▍                        | 40.3 MB 3.5 MB/s eta 0:00:39     |███████▋                        | 41.3 MB 3.5 MB/s eta 0:00:39     |███████▊                        | 42.0 MB 3.5 MB/s eta 0:00:38     |███████████████▉                | 86.1 MB 3.5 MB/s eta 0:00:25     |████████████████                | 86.3 MB 807 kB/s eta 0:01:48     |█████████████████               | 92.6 MB 4.3 MB/s eta 0:00:19     |█████████████████▌              | 94.9 MB 4.3 MB/s eta 0:00:19     |█████████████████▋              | 95.5 MB 4.1 MB/s eta 0:00:20     |█████████████████████           | 114.0 MB 2.8 MB/s eta 0:00:22     |███████████████████████▊        | 128.8 MB 3.2 MB/s eta 0:00:15     |████████████████████████        | 130.3 MB 2.7 MB/s eta 0:00:17     |███████████████████████████▉    | 150.8 MB 3.4 MB/s eta 0:00:07     |███████████████████████████▉    | 151.0 MB 3.4 MB/s eta 0:00:07     |████████████████████████████    | 152.4 MB 3.0 MB/s eta 0:00:07     |█████████████████████████████▉  | 162.0 MB 3.5 MB/s eta 0:00:04     |██████████████████████████████▎ | 164.4 MB 5.0 MB/s eta 0:00:02     |██████████████████████████████▊ | 166.7 MB 3.9 MB/s eta 0:00:02     |███████████████████████████████▎| 169.5 MB 3.9 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ana/.virtualenvs/hckt04/lib/python3.8/site-packages (from xgboost) (1.20.3)\n",
      "Requirement already satisfied: scipy in /home/ana/.virtualenvs/hckt04/lib/python3.8/site-packages (from xgboost) (1.6.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b630acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a column from the dataframe to perform additional transformations on\n",
    "    \"\"\" \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "\n",
    "class TextSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "    \n",
    "class NumberSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ba5bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, feature_names=[\"reviewText\", \"rating\"], label=\"label\"):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[feature_names], df[label], \n",
    "                                                        test_size=0.2, stratify=df[\"label\"])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c02466c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(pipe, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a Random Forest using sklearn's Pipeline and return the trained model and its accuracy in the test set.\n",
    "    \"\"\"\n",
    "    pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d743cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(pipe, X_test):\n",
    "    return pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1569822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_test, y_pred):\n",
    "    f1_score_true_label = f1_score(y_test, y_pred)\n",
    "    classification_report_pred = classification_report(y_test, y_pred)\n",
    "    confusion_matrix_pred = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return f1_score_true_label, classification_report_pred, confusion_matrix_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b00a4a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df_to_process, columns=[\"reviewerID\", \"reviewTime\", \"reviewerName\", \"summary\"]):\n",
    "    \n",
    "    df_copy = df_to_process.copy()\n",
    "    df_copy = df_copy.reset_index()\n",
    "    df_copy = df_copy.drop(columns=[\"reviewerID\", \"reviewTime\", \"reviewerName\", \"summary\"])\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "def drop_columns_taining_set(df_to_process):\n",
    "    df_copy = df_to_process.copy()\n",
    "    return df_copy.drop(columns=[\"overall\", \"rates_count\", \"helpful_count\", \"label_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b67688f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_sub_to_csv(y_sub, name=\"baseline\"):\n",
    "    submission = pd.DataFrame(y_sub)\n",
    "    submission.columns=[\"is_helpful\"]\n",
    "    submission = submission[\"is_helpful\"].astype(str).str.lower()\n",
    "    return submission.to_csv(\"preds/\" + name + '.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39fae0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_label(df, label):\n",
    "    display(df.loc[df_first_iteration['label'] == label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de2e94d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_reviewText(df):\n",
    "    df_copy = df.copy()\n",
    "    return df_copy.loc[df_copy['reviewText'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d44078",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-59afa572e05bc308",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Removing Stop Words and Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff70d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Punctuation and Stop Words\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stopwords(text, stopwords):            \n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    text_processed = \" \".join([token for token in tokens if token not in stopwords])\n",
    "    return text_processed\n",
    "\n",
    "def preprocess_text(df, column):\n",
    "    df_processed = df.copy()\n",
    "    df_processed[column] = df_processed[column].apply(remove_punctuation)\n",
    "    df_processed[column] = df_processed[column].apply(remove_stopwords, stopwords = en_stopwords)\n",
    "    return df_processed\n",
    "\n",
    "def number_of_adv_adj(docs_to_use):\n",
    "    nb_adj_adv = []\n",
    "    matcher = Matcher(nlp.vocab) \n",
    "    matcher.add(\"adv_or_adj\", [[{\"POS\": \"ADJ\"}], [{\"POS\": \"ADV\"}]])\n",
    "    nb_adj_adv = [len(matcher(doc)) for doc in docs_to_use]\n",
    "\n",
    "    return nb_adj_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f78cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_second_iteration = pd.read_csv(\"processed_labelled_data.csv\")\n",
    "df_second_iteration_unlabelled = pd.read_csv(\"processed_unlabelled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efbfdf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_second_iteration_pipeline(number_of_features):\n",
    "    nb_words_pipe = Pipeline([\n",
    "        ('selector', NumberSelector(\"nb_words\")),\n",
    "        ('standard', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    nb_adj_adv_pipe = Pipeline([\n",
    "        ('selector', NumberSelector(\"nb_adj_adv\")),\n",
    "        ('standard', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    ratio_adj_adv_pipe = Pipeline([\n",
    "        ('selector', NumberSelector(\"ratio_adj_adv\")),\n",
    "        ('standard', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    reviewTestPipeline = Pipeline([\n",
    "        ('selector', TextSelector(\"reviewText\")),\n",
    "        ('tfidf', TfidfVectorizer(ngram_range=(1,3))),\n",
    "        ('feature_selection', SelectKBest(chi2, k=number_of_features))\n",
    "    ])\n",
    "\n",
    "    rating = Pipeline([\n",
    "        ('selector', NumberSelector(\"rating\")),\n",
    "        ('standard', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    feats = FeatureUnion([\n",
    "        ('reviewTestPipeline', reviewTestPipeline),\n",
    "        ('rating', rating),\n",
    "        ('ratio_adj_adv', ratio_adj_adv_pipe),\n",
    "        ('nb_words', nb_words_pipe),\n",
    "        ('nb_adj_adv', nb_adj_adv_pipe),\n",
    "    ])\n",
    "\n",
    "    second_iteration_pipeline = Pipeline([\n",
    "        ('features', feats),\n",
    "        ('classifier', RandomForestClassifier()),\n",
    "    ])\n",
    "\n",
    "    return second_iteration_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f90873a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report for number of features 5000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.19      0.50      0.28       696\n",
      "        True       0.91      0.71      0.80      4989\n",
      "\n",
      "    accuracy                           0.69      5685\n",
      "   macro avg       0.55      0.61      0.54      5685\n",
      "weighted avg       0.82      0.69      0.74      5685\n",
      "\n",
      "[[ 347  349]\n",
      " [1435 3554]]\n"
     ]
    }
   ],
   "source": [
    "#for number_of_feats in [100, 1000, 10000, 25000, 50000]:\n",
    "for number_of_feats in [5000]:\n",
    "\n",
    "    second_iteration_pipeline = define_second_iteration_pipeline(number_of_features=number_of_feats)\n",
    "    X_train, X_test, y_train, y_test = split_dataset(df_second_iteration, feature_names=[\"reviewText\", \"rating\", \"nb_adj_adv\", \"nb_words\", \"ratio_adj_adv\"], label=\"label\")\n",
    "    train_pipeline(second_iteration_pipeline, X_train, y_train)\n",
    "    y_val = get_predictions(second_iteration_pipeline, X_test)\n",
    "    f1_score_test, class_report_test, confusion_matrix_test = get_scores(y_val, y_test)\n",
    "    print(\"Report for number of features \" + str(number_of_feats) + \":\")\n",
    "    print(class_report_test)\n",
    "    print(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55980326",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'number_of_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29597/3942377367.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'selector'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextSelector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reviewText\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'feature_selection'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m ])\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'number_of_features' is not defined"
     ]
    }
   ],
   "source": [
    "nb_words_pipe = Pipeline([\n",
    "    ('selector', NumberSelector(\"nb_words\")),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "\n",
    "nb_adj_adv_pipe = Pipeline([\n",
    "    ('selector', NumberSelector(\"nb_adj_adv\")),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "\n",
    "ratio_adj_adv_pipe = Pipeline([\n",
    "    ('selector', NumberSelector(\"ratio_adj_adv\")),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "\n",
    "reviewTestPipeline = Pipeline([\n",
    "    ('selector', TextSelector(\"reviewText\")),\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,3))),\n",
    "    ('feature_selection', SelectKBest(chi2, k=number_of_features))\n",
    "])\n",
    "\n",
    "rating = Pipeline([\n",
    "    ('selector', NumberSelector(\"rating\")),\n",
    "    ('standard', StandardScaler())\n",
    "])\n",
    "\n",
    "feats = FeatureUnion([\n",
    "    ('reviewTestPipeline', reviewTestPipeline),\n",
    "    ('rating', rating),\n",
    "    ('ratio_adj_adv', ratio_adj_adv_pipe),\n",
    "    ('nb_words', nb_words_pipe),\n",
    "    ('nb_adj_adv', nb_adj_adv_pipe),\n",
    "])\n",
    "\n",
    "second_iteration_pipeline = Pipeline([\n",
    "    ('features', feats),\n",
    "    ('classifier', XGBClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5523099",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBClassifier(n_estimators=1200, max_depth=25, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7d949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fb99a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_second_iteration [\"doc_length\"] = df_second_iteration.reviewText.apply(len)\n",
    "df_second_iteration [\"avg_word_length\"] = df_second_iteration.reviewText.apply(lambda x: np.mean([len(word) for word in x.split(\" \")]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42f3d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_second_iteration_pipeline(number_of_features):\n",
    "    nb_words_pipe = Pipeline([\n",
    "        ('selector', NumberSelector(\"nb_words\")),\n",
    "        ('standard', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    nb_adj_adv_pipe = Pipeline([\n",
    "        ('selector', NumberSelector(\"nb_adj_adv\")),\n",
    "        ('standard', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    ratio_adj_adv_pipe = Pipeline([\n",
    "        ('selector', NumberSelector(\"ratio_adj_adv\")),\n",
    "        ('standard', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    reviewTestPipeline = Pipeline([\n",
    "        ('selector', TextSelector(\"reviewText\")),\n",
    "        ('tfidf', TfidfVectorizer(ngram_range=(1,3))),\n",
    "        ('feature_selection', SelectKBest(chi2, k=number_of_features))\n",
    "    ])\n",
    "\n",
    "    rating = Pipeline([\n",
    "        ('selector', NumberSelector(\"rating\")),\n",
    "        ('standard', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    doc_length_pipe =  Pipeline([\n",
    "                ('selector', NumberSelector(\"doc_length\")),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "\n",
    "    avg_word_length_pipe =  Pipeline([\n",
    "                ('selector', NumberSelector(\"avg_word_length\")),\n",
    "                ('standard', StandardScaler())\n",
    "        ])\n",
    "\n",
    "    feats = FeatureUnion([\n",
    "        ('reviewTestPipeline', reviewTestPipeline),\n",
    "        ('rating', rating),\n",
    "        ('ratio_adj_adv', ratio_adj_adv_pipe),\n",
    "        ('nb_words', nb_words_pipe),\n",
    "        ('nb_adj_adv', nb_adj_adv_pipe),\n",
    "        ('doc_length', doc_length_pipe),\n",
    "        ('avg_word_length', avg_word_length_pipe)\n",
    "    ])\n",
    "\n",
    "    second_iteration_pipeline = Pipeline([\n",
    "        ('features', feats),\n",
    "        ('classifier', RandomForestClassifier()),\n",
    "    ])\n",
    "\n",
    "    return second_iteration_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e98ffbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "493706bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report for number of features 5000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.19      0.54      0.28       634\n",
      "        True       0.93      0.72      0.81      5051\n",
      "\n",
      "    accuracy                           0.70      5685\n",
      "   macro avg       0.56      0.63      0.55      5685\n",
      "weighted avg       0.84      0.70      0.75      5685\n",
      "\n",
      "[[ 344  290]\n",
      " [1438 3613]]\n"
     ]
    }
   ],
   "source": [
    "#for number_of_feats in [100, 1000, 10000, 25000, 50000]:\n",
    "for number_of_feats in [5000]:\n",
    "\n",
    "    second_iteration_pipeline = define_second_iteration_pipeline(number_of_features=number_of_feats)\n",
    "    X_train, X_test, y_train, y_test = split_dataset(df_second_iteration, feature_names=[\"reviewText\", \"rating\", \"nb_adj_adv\", \"nb_words\", \"ratio_adj_adv\", 'doc_length', 'avg_word_length'], label=\"label\")\n",
    "    train_pipeline(second_iteration_pipeline, X_train, y_train)\n",
    "    y_val = get_predictions(second_iteration_pipeline, X_test)\n",
    "    f1_score_test, class_report_test, confusion_matrix_test = get_scores(y_val, y_test)\n",
    "    print(\"Report for number of features \" + str(number_of_feats) + \":\")\n",
    "    print(class_report_test)\n",
    "    print(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d51516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee8b03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d64ce91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_samples = df_second_iteration.loc[df_second_iteration[\"label\"] == True]\n",
    "false_samples = df_second_iteration.loc[df_second_iteration[\"label\"] == False]\n",
    "false_samples_size = false_samples.shape[0]\n",
    "\n",
    "true_samples_rebalance = true_samples.sample(n=false_samples_size)\n",
    "\n",
    "balanced_df = pd.concat([false_samples, true_samples_rebalance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69c86ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report for number of features 5000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.62      0.61      1705\n",
      "        True       0.64      0.61      0.63      1859\n",
      "\n",
      "    accuracy                           0.62      3564\n",
      "   macro avg       0.62      0.62      0.62      3564\n",
      "weighted avg       0.62      0.62      0.62      3564\n",
      "\n",
      "[[1065  640]\n",
      " [ 717 1142]]\n"
     ]
    }
   ],
   "source": [
    "#for number_of_feats in [100, 1000, 10000, 25000, 50000]:\n",
    "for number_of_feats in [5000]:\n",
    "\n",
    "    second_iteration_pipeline = define_second_iteration_pipeline(number_of_features=number_of_feats)\n",
    "    X_train, X_test, y_train, y_test = split_dataset(balanced_df, feature_names=[\"reviewText\", \"rating\", \"nb_adj_adv\", \"nb_words\", \"ratio_adj_adv\", 'doc_length', 'avg_word_length'], label=\"label\")\n",
    "    train_pipeline(second_iteration_pipeline, X_train, y_train)\n",
    "    y_val = get_predictions(second_iteration_pipeline, X_test)\n",
    "    f1_score_test, class_report_test, confusion_matrix_test = get_scores(y_val, y_test)\n",
    "    print(\"Report for number of features \" + str(number_of_feats) + \":\")\n",
    "    print(class_report_test)\n",
    "    print(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf6f7ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report for number of features 5000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.61      0.61      1780\n",
      "        True       0.61      0.61      0.61      1784\n",
      "\n",
      "    accuracy                           0.61      3564\n",
      "   macro avg       0.61      0.61      0.61      3564\n",
      "weighted avg       0.61      0.61      0.61      3564\n",
      "\n",
      "[[1093  687]\n",
      " [ 689 1095]]\n"
     ]
    }
   ],
   "source": [
    "#for number_of_feats in [100, 1000, 10000, 25000, 50000]:\n",
    "for number_of_feats in [5000]:\n",
    "\n",
    "    second_iteration_pipeline = define_second_iteration_pipeline(number_of_features=number_of_feats)\n",
    "    X_train, X_test, y_train, y_test = split_dataset(balanced_df, feature_names=[\"reviewText\", \"rating\", \"nb_adj_adv\", \"nb_words\", \"ratio_adj_adv\"], label=\"label\")\n",
    "    train_pipeline(second_iteration_pipeline, X_train, y_train)\n",
    "    y_val = get_predictions(second_iteration_pipeline, X_test)\n",
    "    f1_score_test, class_report_test, confusion_matrix_test = get_scores(y_val, y_test)\n",
    "    print(\"Report for number of features \" + str(number_of_feats) + \":\")\n",
    "    print(class_report_test)\n",
    "    print(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b6937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c534803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14119cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1; python_version >= \"3\" in /home/ana/.virtualenvs/hckt04/lib/python3.8/site-packages (from textblob) (3.6.2)\n",
      "Requirement already satisfied: regex in /home/ana/.virtualenvs/hckt04/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (2021.11.2)\n",
      "Requirement already satisfied: click in /home/ana/.virtualenvs/hckt04/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (7.1.1)\n",
      "Requirement already satisfied: joblib in /home/ana/.virtualenvs/hckt04/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /home/ana/.virtualenvs/hckt04/lib/python3.8/site-packages (from nltk>=3.1; python_version >= \"3\"->textblob) (4.62.3)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64a0656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "df_sa = df_second_iteration.copy()\n",
    "\n",
    "pol = lambda x: TextBlob(x).sentiment.polarity\n",
    "sub = lambda x: TextBlob(x).sentiment.subjectivity\n",
    "\n",
    "df_sa['polarity'] = df_sa['reviewText'].apply(lambda x: pol(x) )\n",
    "df_sa['subjectivity'] = df_sa['reviewText'].apply(lambda x: sub(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c92254a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>nb_adj_adv</th>\n",
       "      <th>nb_words</th>\n",
       "      <th>ratio_adj_adv</th>\n",
       "      <th>doc_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jenkins history professor member parliament au...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "      <td>144</td>\n",
       "      <td>0.340278</td>\n",
       "      <td>1245</td>\n",
       "      <td>7.652778</td>\n",
       "      <td>0.121264</td>\n",
       "      <td>0.434615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>didnt read purchased gift family small childre...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>62</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fierce angels sheri park reads like dissertati...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "      <td>134</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>976</td>\n",
       "      <td>6.291045</td>\n",
       "      <td>0.041026</td>\n",
       "      <td>0.604487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>clearly author goals mind 1 advantage american...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>355</td>\n",
       "      <td>6.120000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.688095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>collection stories memories japanese soldiers ...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>114</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>882</td>\n",
       "      <td>6.745614</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.357738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28417</th>\n",
       "      <td>28418</td>\n",
       "      <td>daniel klein coauthor thomas cathcart wonderfu...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>113</td>\n",
       "      <td>0.265487</td>\n",
       "      <td>868</td>\n",
       "      <td>6.690265</td>\n",
       "      <td>0.274407</td>\n",
       "      <td>0.467278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28418</th>\n",
       "      <td>28419</td>\n",
       "      <td>golden book 1962 illustrations great text good...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>238</td>\n",
       "      <td>6.242424</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.718393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28419</th>\n",
       "      <td>28420</td>\n",
       "      <td>initially attracted book main characters math ...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "      <td>106</td>\n",
       "      <td>0.292453</td>\n",
       "      <td>807</td>\n",
       "      <td>6.622642</td>\n",
       "      <td>0.215789</td>\n",
       "      <td>0.478446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28420</th>\n",
       "      <td>28421</td>\n",
       "      <td>intriguing mystery compelling romance charlies...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>345</td>\n",
       "      <td>6.208333</td>\n",
       "      <td>0.324242</td>\n",
       "      <td>0.593939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28421</th>\n",
       "      <td>28422</td>\n",
       "      <td>oh power words book powerfullly explores words...</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>304</td>\n",
       "      <td>6.820513</td>\n",
       "      <td>0.377116</td>\n",
       "      <td>0.649339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28422 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                         reviewText  rating  \\\n",
       "0               0  jenkins history professor member parliament au...       4   \n",
       "1               1  didnt read purchased gift family small childre...       3   \n",
       "2               2  fierce angels sheri park reads like dissertati...       4   \n",
       "3               3  clearly author goals mind 1 advantage american...       1   \n",
       "4               4  collection stories memories japanese soldiers ...       5   \n",
       "...           ...                                                ...     ...   \n",
       "28417       28418  daniel klein coauthor thomas cathcart wonderfu...       4   \n",
       "28418       28419  golden book 1962 illustrations great text good...       5   \n",
       "28419       28420  initially attracted book main characters math ...       5   \n",
       "28420       28421  intriguing mystery compelling romance charlies...       5   \n",
       "28421       28422  oh power words book powerfullly explores words...       4   \n",
       "\n",
       "       label  nb_adj_adv  nb_words  ratio_adj_adv  doc_length  \\\n",
       "0       True          49       144       0.340278        1245   \n",
       "1      False           2        10       0.200000          62   \n",
       "2       True          41       134       0.305970         976   \n",
       "3       True          15        50       0.300000         355   \n",
       "4       True          39       114       0.342105         882   \n",
       "...      ...         ...       ...            ...         ...   \n",
       "28417   True          30       113       0.265487         868   \n",
       "28418   True          10        33       0.303030         238   \n",
       "28419   True          31       106       0.292453         807   \n",
       "28420   True          18        48       0.375000         345   \n",
       "28421   True          17        39       0.435897         304   \n",
       "\n",
       "       avg_word_length  polarity  subjectivity  \n",
       "0             7.652778  0.121264      0.434615  \n",
       "1             5.300000  0.225000      0.500000  \n",
       "2             6.291045  0.041026      0.604487  \n",
       "3             6.120000 -0.100000      0.688095  \n",
       "4             6.745614  0.076190      0.357738  \n",
       "...                ...       ...           ...  \n",
       "28417         6.690265  0.274407      0.467278  \n",
       "28418         6.242424  0.495000      0.718393  \n",
       "28419         6.622642  0.215789      0.478446  \n",
       "28420         6.208333  0.324242      0.593939  \n",
       "28421         6.820513  0.377116      0.649339  \n",
       "\n",
       "[28422 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b0804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b016925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_second_iteration_pipeline(number_of_features):\n",
    "    nb_words_pipe = Pipeline([\n",
    "        ('selector', NumberSelector(\"nb_words\")),\n",
    "        ('standard', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    nb_adj_adv_pipe = Pipeline([\n",
    "        ('selector', NumberSelector(\"nb_adj_adv\")),\n",
    "        ('standard', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    ratio_adj_adv_pipe = Pipeline([\n",
    "        ('selector', NumberSelector(\"ratio_adj_adv\")),\n",
    "        ('standard', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    reviewTestPipeline = Pipeline([\n",
    "        ('selector', TextSelector(\"reviewText\")),\n",
    "        ('tfidf', TfidfVectorizer(ngram_range=(1,3))),\n",
    "        ('feature_selection', SelectKBest(chi2, k=number_of_features))\n",
    "    ])\n",
    "\n",
    "    rating = Pipeline([\n",
    "        ('selector', NumberSelector(\"rating\")),\n",
    "        ('standard', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    doc_length_pipe =  Pipeline([\n",
    "                ('selector', NumberSelector(\"doc_length\")),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "\n",
    "    avg_word_length_pipe =  Pipeline([\n",
    "                ('selector', NumberSelector(\"avg_word_length\")),\n",
    "                ('standard', StandardScaler())\n",
    "        ])\n",
    "    \n",
    "    polarity_pipe = Pipeline([\n",
    "        ('selector', NumberSelector(\"polarity\")),\n",
    "        ('standard', StandardScaler())\n",
    "        ])\n",
    "\n",
    "    subjectivity_pipe = Pipeline([\n",
    "        ('selector', NumberSelector(\"subjectivity\")),\n",
    "        ('standard', StandardScaler())\n",
    "        ])\n",
    "\n",
    "\n",
    "    feats = FeatureUnion([\n",
    "        ('reviewTestPipeline', reviewTestPipeline),\n",
    "        ('rating', rating),\n",
    "        ('ratio_adj_adv', ratio_adj_adv_pipe),\n",
    "        ('nb_words', nb_words_pipe),\n",
    "        ('nb_adj_adv', nb_adj_adv_pipe),\n",
    "        ('doc_length', doc_length_pipe),\n",
    "        ('avg_word_length', avg_word_length_pipe),\n",
    "        ('polarity', polarity_pipe),\n",
    "        ('subjectivity', subjectivity_pipe)\n",
    "    ])\n",
    "\n",
    "    second_iteration_pipeline = Pipeline([\n",
    "        ('features', feats),\n",
    "        ('classifier', RandomForestClassifier()),\n",
    "    ])\n",
    "\n",
    "    return second_iteration_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d1478f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_second_iteration = df_sa\n",
    "true_samples = df_second_iteration.loc[df_second_iteration[\"label\"] == True]\n",
    "false_samples = df_second_iteration.loc[df_second_iteration[\"label\"] == False]\n",
    "false_samples_size = false_samples.shape[0]\n",
    "\n",
    "true_samples_rebalance = true_samples.sample(n=false_samples_size)\n",
    "\n",
    "balanced_df = pd.concat([false_samples, true_samples_rebalance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9967c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>nb_adj_adv</th>\n",
       "      <th>nb_words</th>\n",
       "      <th>ratio_adj_adv</th>\n",
       "      <th>doc_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>didnt read purchased gift family small childre...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>62</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>read thisi gave star wanted attention cos got ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>204</td>\n",
       "      <td>5.029412</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.842857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>wait book triology come interesting type myste...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>92</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>bill bryson funny guy complex things language ...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>512</td>\n",
       "      <td>6.772727</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.622500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>philip roth authors read matter excellent styl...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>125</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>902</td>\n",
       "      <td>6.224000</td>\n",
       "      <td>0.064232</td>\n",
       "      <td>0.642620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>11818</td>\n",
       "      <td>admit naving seen sean hannity fox news liked ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>348</td>\n",
       "      <td>5.843137</td>\n",
       "      <td>0.147619</td>\n",
       "      <td>0.372619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26422</th>\n",
       "      <td>26423</td>\n",
       "      <td>fun read seattle meaningful loved email letter...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>102</td>\n",
       "      <td>5.866667</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11294</th>\n",
       "      <td>11295</td>\n",
       "      <td>diet book fad diet book simply diet try months...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "      <td>125</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>884</td>\n",
       "      <td>6.080000</td>\n",
       "      <td>0.179309</td>\n",
       "      <td>0.449916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19540</th>\n",
       "      <td>19541</td>\n",
       "      <td>enjoyed humorous insightful book learned new t...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>104</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>718</td>\n",
       "      <td>5.913462</td>\n",
       "      <td>0.126124</td>\n",
       "      <td>0.582023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11599</th>\n",
       "      <td>11600</td>\n",
       "      <td>fun read fools gold book exactly girl meets bo...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>199</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.287500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17820 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                         reviewText  rating  \\\n",
       "1               1  didnt read purchased gift family small childre...       3   \n",
       "10             10  read thisi gave star wanted attention cos got ...       1   \n",
       "11             11  wait book triology come interesting type myste...       5   \n",
       "12             12  bill bryson funny guy complex things language ...       5   \n",
       "14             14  philip roth authors read matter excellent styl...       5   \n",
       "...           ...                                                ...     ...   \n",
       "11817       11818  admit naving seen sean hannity fox news liked ...       1   \n",
       "26422       26423  fun read seattle meaningful loved email letter...       5   \n",
       "11294       11295  diet book fad diet book simply diet try months...       5   \n",
       "19540       19541  enjoyed humorous insightful book learned new t...       5   \n",
       "11599       11600  fun read fools gold book exactly girl meets bo...       3   \n",
       "\n",
       "       label  nb_adj_adv  nb_words  ratio_adj_adv  doc_length  \\\n",
       "1      False           2        10       0.200000          62   \n",
       "10     False          12        34       0.352941         204   \n",
       "11     False           5        15       0.333333          92   \n",
       "12     False          18        66       0.272727         512   \n",
       "14     False          33       125       0.264000         902   \n",
       "...      ...         ...       ...            ...         ...   \n",
       "11817   True          10        51       0.196078         348   \n",
       "26422   True           7        15       0.466667         102   \n",
       "11294   True          55       125       0.440000         884   \n",
       "19540   True          46       104       0.442308         718   \n",
       "11599   True           8        30       0.266667         199   \n",
       "\n",
       "       avg_word_length  polarity  subjectivity  \n",
       "1             5.300000  0.225000      0.500000  \n",
       "10            5.029412  0.371429      0.842857  \n",
       "11            5.200000  0.250000      0.250000  \n",
       "12            6.772727  0.317500      0.622500  \n",
       "14            6.224000  0.064232      0.642620  \n",
       "...                ...       ...           ...  \n",
       "11817         5.843137  0.147619      0.372619  \n",
       "26422         5.866667  0.212500      0.733333  \n",
       "11294         6.080000  0.179309      0.449916  \n",
       "19540         5.913462  0.126124      0.582023  \n",
       "11599         5.666667  0.387500      0.287500  \n",
       "\n",
       "[17820 rows x 11 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2fcb7197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report for number of features 5000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      0.63      0.64      1856\n",
      "        True       0.62      0.64      0.63      1708\n",
      "\n",
      "    accuracy                           0.64      3564\n",
      "   macro avg       0.64      0.64      0.64      3564\n",
      "weighted avg       0.64      0.64      0.64      3564\n",
      "\n",
      "[[1171  685]\n",
      " [ 611 1097]]\n"
     ]
    }
   ],
   "source": [
    "#for number_of_feats in [100, 1000, 10000, 25000, 50000]:\n",
    "for number_of_feats in [5000]:\n",
    "\n",
    "    second_iteration_pipeline = define_second_iteration_pipeline(number_of_features=number_of_feats)\n",
    "    X_train, X_test, y_train, y_test = split_dataset(balanced_df, feature_names=[\"reviewText\", \"rating\", \"nb_adj_adv\", \"nb_words\", \"ratio_adj_adv\", 'doc_length', 'avg_word_length', \"polarity\", \"subjectivity\"], label=\"label\")\n",
    "    train_pipeline(second_iteration_pipeline, X_train, y_train)\n",
    "    y_val = get_predictions(second_iteration_pipeline, X_test)\n",
    "    f1_score_test, class_report_test, confusion_matrix_test = get_scores(y_val, y_test)\n",
    "    print(\"Report for number of features \" + str(number_of_feats) + \":\")\n",
    "    print(class_report_test)\n",
    "    print(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc28ed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report for number of features 5000:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.20      0.55      0.29       637\n",
      "        True       0.93      0.72      0.81      5048\n",
      "\n",
      "    accuracy                           0.70      5685\n",
      "   macro avg       0.56      0.63      0.55      5685\n",
      "weighted avg       0.84      0.70      0.75      5685\n",
      "\n",
      "[[ 350  287]\n",
      " [1432 3616]]\n"
     ]
    }
   ],
   "source": [
    "#for number_of_feats in [100, 1000, 10000, 25000, 50000]:\n",
    "for number_of_feats in [5000]:\n",
    "\n",
    "    second_iteration_pipeline = define_second_iteration_pipeline(number_of_features=number_of_feats)\n",
    "    X_train, X_test, y_train, y_test = split_dataset(df_second_iteration, feature_names=[\"reviewText\", \"rating\", \"nb_adj_adv\", \"nb_words\", \"ratio_adj_adv\", 'doc_length', 'avg_word_length', \"polarity\", \"subjectivity\"], label=\"label\")\n",
    "    train_pipeline(second_iteration_pipeline, X_train, y_train)\n",
    "    y_val = get_predictions(second_iteration_pipeline, X_test)\n",
    "    f1_score_test, class_report_test, confusion_matrix_test = get_scores(y_val, y_test)\n",
    "    print(\"Report for number of features \" + str(number_of_feats) + \":\")\n",
    "    print(class_report_test)\n",
    "    print(confusion_matrix_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
